{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-PW-2023\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datasets import Dataset\n",
    "\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer, \n",
    "    TrainingArguments, Trainer, \n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.utils import logging\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring warnings, info and debug \n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nvidia gpu (more efficient)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading environmental variables\n",
    "load_dotenv()\n",
    "\n",
    "PARENT_DIR = os.environ.get(\"PARENT_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... Done\n"
     ]
    }
   ],
   "source": [
    "# loading model from HuggingFace\n",
    "print(\"Loading model... \", end='', flush=True)\n",
    "tokeniser = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "model.to(device)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Question', 'Answer'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset from Huggingface\n",
    "# raw_dataset = load_dataset(\"vicgalle/alpaca-gpt4\", split=\"train\")\n",
    "# raw_dataset = raw_dataset.shuffle(seed=42).select(range(10))\n",
    "\n",
    "# loading dataset from csv file\n",
    "raw_dataset = None\n",
    "base_qa = []\n",
    "augmented_qa = []\n",
    "\n",
    "with open(PARENT_DIR + \"src/data/base_data.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for q, a in list(csvreader)[1:]:\n",
    "        base_qa.append((q,a))\n",
    "\n",
    "with open(PARENT_DIR + \"src/data/processed_data.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    val = [*filter(lambda v: v, csvreader)][1:]\n",
    "    for q, a in val:\n",
    "        augmented_qa.append((q,a))\n",
    "random.shuffle(augmented_qa)\n",
    "\n",
    "# ensure that all of the base data is appended, limiting the augmented data as it is more inaccurate\n",
    "qa = base_qa + base_qa + augmented_qa\n",
    "random.shuffle(qa)\n",
    "\n",
    "qa = qa[:2000]\n",
    "\n",
    "raw_dataset = Dataset.from_dict({\"Question\" : [q for q, _ in qa], \"Answer\" : [a for _, a in qa]})\n",
    "\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': [\"Recite me about hci 's account .\",\n",
       "  'Can you picture me a map of hci ?',\n",
       "  'What leisure time activity are worthy for soul concerned in the hci field ?',\n",
       "  'Where can i pose notes ?',\n",
       "  'When be hci founded ?'],\n",
       " 'Answer': [\"Hwa Chong Institution (HCI) is Singapore's independent school with a rich history of over 100 years.  The Institution is the culmination of the watershed merger in 2005 between the former Chinese High School (TCHS) and Hwa Chong Junior College (HCJC). The then Chinese High School (TCHS) was founded by Mr Tan Kah Kee in 1919 to cater to the needs of primary school leavers of the Chinese community in the region. It became the first Chinese-language secondary school in South-east Asia. Entering Singaporeâ€™s post-independence era, TCHS was designated by the Ministry of Education (MOE) as one of nine Special Assistance Plan (SAP) Schools in the nation in 1979, before turning independent in 1987.\",\n",
       "  'Sure! Here it is: https://www.hci.edu.sg/images/hci_map_2023F3.jpg',\n",
       "  'In HCI, there are many different facilities you can go to after school. Do note that some of these facilities require booking, hence check before going there to have fun. That being said, you could go to the basketball court, library, ping pong tables or take a walk in the consortium gardens. The track is also an option, though do note that track and field CCA is held there and it woukd be wise to not bother them. Hope this helps!',\n",
       "  'You can check out HCNotes! Here is the link: https://50thhsc.notion.site/HC-NOTES-2023-9db11009754a4d8b94f347f5d1033bc3',\n",
       "  'The Chinese High School, aka present day HCI was founded in 1919, but changed its name from The Chinese High School to HCI in 2005, where a merger between The Chinese High School and Hwa Chong Junior College occurred. ']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-formatting dataset: 100%|██████████| 2000/2000 [00:00<00:00, 12916.52 rows/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reformatting dataset for training\n",
    "temp_lst = []\n",
    "\n",
    "for row in tqdm.tqdm(raw_dataset, desc=\"Re-formatting dataset\", unit=\" rows\"):\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"text\"] = row[\"Question\"].strip() + tokeniser.eos_token + row[\"Answer\"].strip() + tokeniser.eos_token\n",
    "    temp_lst.append(temp_dict)\n",
    "\n",
    "temp_df = pd.DataFrame(temp_lst, columns=[\"text\"])\n",
    "temp_df.dropna()\n",
    "\n",
    "processed_dataset = Dataset.from_pandas(temp_df)\n",
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 2470.28 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 1800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenising dataset for training\n",
    "tokeniser.pad_token = tokeniser.eos_token\n",
    "\n",
    "def preprocess(example):\n",
    "    return tokeniser(example[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenised_dataset = processed_dataset.map(preprocess)\n",
    "\n",
    "tokenised_dataset = tokenised_dataset.remove_columns([\"text\"])\n",
    "tokenised_dataset = tokenised_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "tokenised_dataset = tokenised_dataset.train_test_split(test_size=0.1)\n",
    "tokenised_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Collator...Done\n"
     ]
    }
   ],
   "source": [
    "# creating data collator as substitute for label\n",
    "print(\"Creating Data Collator...\", end=\"\")\n",
    "data_collator = DataCollatorForLanguageModeling(tokeniser, mlm=False) # ensure that mode is clm \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be saved as : `model-132744`\n"
     ]
    }
   ],
   "source": [
    "# generating model id\n",
    "model_id = \"model-\" + datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "print(\"Model will be saved as :\", f\"`{model_id}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up arguments for training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = PARENT_DIR + f\"models/{model_id}\",\n",
    "    overwrite_output_dir = True,\n",
    "    disable_tqdm = False,\n",
    "    do_eval = True,\n",
    "    do_train = True,\n",
    "    do_predict = True,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    save_on_each_node = True,\n",
    "    optim = \"adamw_torch\",\n",
    "    report_to = \"all\",\n",
    "    load_best_model_at_end = True,\n",
    "    num_train_epochs = 5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_dataset[\"train\"],\n",
    "    eval_dataset=tokenised_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokeniser,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|██        | 225/1125 [31:07<2:05:44,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36185622215270996, 'eval_runtime': 68.8416, 'eval_samples_per_second': 2.905, 'eval_steps_per_second': 0.363, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 40%|████      | 450/1125 [1:01:13<1:23:31,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28516989946365356, 'eval_runtime': 67.5401, 'eval_samples_per_second': 2.961, 'eval_steps_per_second': 0.37, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 500/1125 [1:07:15<1:06:27,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7043, 'learning_rate': 2.777777777777778e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 60%|██████    | 675/1125 [1:31:58<55:55,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2631673812866211, 'eval_runtime': 69.0757, 'eval_samples_per_second': 2.895, 'eval_steps_per_second': 0.362, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 80%|████████  | 900/1125 [2:01:59<27:45,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2520483732223511, 'eval_runtime': 67.2807, 'eval_samples_per_second': 2.973, 'eval_steps_per_second': 0.372, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1000/1125 [2:15:18<13:58,  6.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1862, 'learning_rate': 5.555555555555556e-06, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 1125/1125 [2:31:58<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2488832026720047, 'eval_runtime': 65.4016, 'eval_samples_per_second': 3.058, 'eval_steps_per_second': 0.382, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [2:32:00<00:00,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 9120.6091, 'train_samples_per_second': 0.987, 'train_steps_per_second': 0.123, 'train_loss': 0.4142701212565104, 'epoch': 5.0}\n",
      "Saving model...Done\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "train_output = trainer.train()\n",
    "\n",
    "# saving model\n",
    "print(\"Saving model...\", end=\"\")\n",
    "trainer.save_model(PARENT_DIR + f\"models/{model_id}/final\")  \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Training Completed ==\n",
      "Global Step : 1125\n",
      "Training Loss : 0.41427\n",
      "Metrics :\n",
      "  • Train Runtime : 9120.6091\n",
      "  • Train Samples Per Second : 0.987\n",
      "  • Train Steps Per Second : 0.123\n",
      "  • Train Loss : 0.41427\n",
      "  • Epoch : 5.0\n"
     ]
    }
   ],
   "source": [
    "# printing summary of model\n",
    "data = {\n",
    "    \"global_step\": train_output.global_step,\n",
    "    \"training_loss\": train_output.training_loss,\n",
    "    \"metrics\": train_output.metrics,\n",
    "}\n",
    "\n",
    "data[\"metrics\"] = [(key, value) for key, value in train_output.metrics.items()]\n",
    "\n",
    "print(\"== Training Completed ==\")\n",
    "for i, val in enumerate(data.items()):\n",
    "    k, v = val\n",
    "    if i < 2:\n",
    "        print(\" \".join([j.capitalize() for j in k.split(\"_\")]), \":\", round(v, 5))\n",
    "    else:\n",
    "        print(\" \".join([j.capitalize() for j in k.split(\"_\")]), \":\")\n",
    "        for f, s in v:\n",
    "            print(\"  •\", \" \".join([j.replace(\"eval\", \"evaluation\").capitalize() for j in f.split(\"_\")]), \":\", round(s, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
